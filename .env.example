## customize your configurations here
## settings in this file will cover default ones

# ==========================
# LLM Provider Configuration
# ==========================
# "gpt" / "deepseek"
LLM_PROVIDER=deepseek

# --- OpenAI GPT ---
OPENAI_API_KEY=
OPENAI_BASE_URL=https://api.chatanywhere.tech/v1/chat/completions
# gpt-4o / gpt-4o-mini
OPENAI_MODEL=gpt-4o

# --- DeepSeek ---
DEEPSEEK_API_KEY=
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1/chat/completions
# deepseek-chat / deepseek-reasoner
DEEPSEEK_MODEL=deepseek-chat

# ==========================
# Data Paths (path under project root)
# ==========================
INPUT_PATH=data/input/raw_data/labels
OUTPUT_PATH=data/output

# ==========================
# Processing Parameters
# ==========================
# data processing per LLM request
BATCH_SIZE=50

# results within cofidence below threshold will be sent to LLM
# TODO: not alining with paper (should be 1.1?)
CONFIDENCE_THRESHOLD=1.01

# Include ground truth in prompt (true/false)
INCLUDE_GT_IN_PROMPT=false

# Max reference tokens
REFERENCE_MAX_TOKENS=120

# ==========================
# Logging
# ==========================

# Logging verbosity: 0=warn, 1=info, 2=debug
VERBOSITY=0

# Optional log file path (leave empty to disable file logging)
LOG_FILE=logs.log
